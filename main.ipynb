{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('pt': conda)",
   "metadata": {
    "interpreter": {
     "hash": "f2de9bcdbc0b3e6f51c80540c0a0a7a55c483877f43ec5f7671a754e5d380086"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run helpers.py\n",
    "%run classification.py\n",
    "%run transformations.py\n",
    "%run model.py\n",
    "%run prediction.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import classification\n",
    "import helpers\n",
    "import transformations as tr\n",
    "import model\n",
    "import prediction\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_cmdline_arguments():\n",
    "    \"\"\"Parse command line arguments\"\"\"\n",
    "    parser = argparse.ArgumentParser(description='Image classification...')\n",
    "    parser.add_argument('-d', '--dir_path', type=str, default=(os.getcwd() + '\\\\data\\\\part1'),\n",
    "                        help='Full path of dataset containing images')\n",
    "    parser.add_argument('-t', '--test_images_path', type=str, default=(os.getcwd() + '\\\\data\\\\part1\\\\bristol\\\\person_2'),\n",
    "                        help='Full path of dataset containing test images')\n",
    "    parser.add_argument('--csv_file_dir', type=str, default=(os.getcwd() + '\\\\data\\\\part2'),\n",
    "                        help='csv file directory having bbox for images')\n",
    "    parser.add_argument('-m', '--pretrained_model', type=str.lower,\n",
    "                        choices=['resnet34', 'resnet50'],\n",
    "                        default='resnet34', help='Pretrained base model name')\n",
    "    parser.add_argument('-e', '--epochs', type=int, default=3,  help='No. of epochs')\n",
    "    parser.add_argument('--activation', type=str.lower, choices=['relu'],\n",
    "                        default='relu', help='Activation function')\n",
    "    parser.add_argument('-bs', '--batch_size', type=int, default=4,\n",
    "                        help='Batch size')\n",
    "    parser.add_argument('-lr', '--learning_rate', type=float, default=0.001,\n",
    "                        help='Learning rate')\n",
    "    # parser.add_argument('--dropout', type=float, default=0.0,\n",
    "                        # help='Dropout fraction')\n",
    "    # parser.add_argument('--augment', action='store_true',\n",
    "                        # help='Perform image augmentation')\n",
    "    # parser.add_argument('--ckpt_period_and_path', type=str, nargs=2,\n",
    "                        # default=[1000, 'training/cp-{epoch:04d}.ckpt'],\n",
    "                        # help='Save checkpoints every <period> steps at <dir>')\n",
    "    parser.add_argument('-v', '--verbose', action=\"store_true\",\n",
    "                        help='Increase output verbosity')\n",
    "\n",
    "    return parser.parse_args(args=[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    args = parse_cmdline_arguments()\n",
    "    \n",
    "    # dir_path =  args.dir_path if args.dir_path else (os.getcwd() + '\\\\data\\\\part1')\n",
    "    helpers.check_path_exists(args.dir_path, 'train images directory')\n",
    "    \n",
    "    df_player_info, teams_dic, players_dic = helpers.generate_player_info(args.dir_path, check_invalid_images_flag=False)\n",
    "\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406])\n",
    "    std = torch.tensor([0.229, 0.224, 0.225])\n",
    "    train_transform = transforms.Compose([tr.Resize(224, 224), tr.ToTensor(), tr.Normalization(mean,std)])\n",
    "    test_transform = transforms.Compose([tr.Resize(224, 224), tr.ToTensor(), tr.Normalization(mean,std)])\n",
    "\n",
    "    # Split the data in training and validation setl\n",
    "    data = helpers.split_data(df_player_info, test_size=0.2)\n",
    "\n",
    "    data['train'] = classification.Classification(player_info=data['train'], transform=train_transform)\n",
    "    data['valid'] = classification.Classification(player_info=data['valid'], transform=train_transform)\n",
    "    \n",
    "    train_dataloader = DataLoader(dataset=data['train'], batch_size=args.batch_size, shuffle=True, num_workers=0)\n",
    "    valid_dataloader = DataLoader(dataset=data['valid'], batch_size=args.batch_size, shuffle=False, num_workers=0)\n",
    "    dataloaders = {phase:train_dataloader if phase == 'train' else valid_dataloader for phase in ['train', 'valid']}\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    device = torch.device(\"cpu\")\n",
    "    # Setting model and moving to device\n",
    "    model_CNN = model.Model(True, args.pretrained_model, len(teams_dic), len(players_dic)).to(device)\n",
    "    # For multilabel output: Same criterion here for 'teams' and 'players', but can change as required\n",
    "    criterions = {phase:nn.CrossEntropyLoss() if phase == 'teams' else nn.CrossEntropyLoss() for phase in ['teams', 'players']}\n",
    "    optimizer = optim.SGD(model_CNN.parameters(), lr=args.learning_rate, momentum=0.9)\n",
    "\n",
    "    model_CNN = model_CNN.train_model(model_CNN, dataloaders, criterions, optimizer, device)\n",
    "    print('\\ndone training...')\n",
    "    torch.save(model_CNN.state_dict(), 'model_CNN.ckpt')\n",
    "    model_CNN.load_state_dict(torch.load('model_CNN.ckpt'))\n",
    "\n",
    "    predict = prediction.Prediction(model_CNN, test_transform)\n",
    "    \n",
    "    # test_images_path = args.test_images_path if args.test_images_path else (os.getcwd() + '\\\\data\\\\part1\\\\bristol\\\\person_2')\n",
    "    helpers.check_path_exists(args.test_images_path, 'test images directory')\n",
    "    # predict.predict_images_in_directory(args.test_images_path, check_invalid_images_flag=False)\n",
    "    \n",
    "    # csv_file_dir = args.test_images_path if args.test_images_path else (os.getcwd() + '\\\\data\\\\part1\\\\bristol\\\\person_2')\n",
    "    predict.predict_and_color_section_of_images(args.csv_file_dir)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ]
}